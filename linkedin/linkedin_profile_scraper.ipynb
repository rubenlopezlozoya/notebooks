{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install linkedin-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.cookies import RequestsCookieJar\n",
    "from linkedin_api import Linkedin\n",
    "\n",
    "LINKEDIN_EMAIL = 'rubenlopezlozoya12@gmail.com'\n",
    "LINKEDIN_PASSWORD = '<PASSWORD>'\n",
    "cookie_string = 'bscookie=\"v=1&202303061639463445695f-56e3-4100-8991-4989ced57cbeAQFetGcqbhvmdfCIHeHUPvvsf8lZkCH7\"; li_alerts=e30=; g_state={\"i_l\":0}; li_theme=light; li_theme_set=app; bcookie=\"v=2&2f4de5c0-ebaf-46bc-8f30-6395abd1d29e\"; dfpfpt=187af7de4da940f7846e9c86420c26ad; visit=v=1&M; timezone=Europe/Madrid; li_rm=AQGN_zJO-ZIfwgAAAZDmZBe9yw18cHm5CqgjeRwt4e7Iwr0BFMIf_EBTQGskP8lXcnXrlaJjAfdcbwIc7P2ZqRsuBWj69EP8KHczL1rUkr298R456bmcXr6MavbMWo3faRmKeYMg4d4KIVvv9MASE7FGtXaP-WCIufvGc99ASmM1zU8DabxWtISryAluThbdF0leFlPsd78ZDgM7dEUB_BS1UtTJqNMYITJyLVDPo47pOfYsfPxc1C9Vknf7AqoZFUGerEcus0RbqlVVx8ztL6J_SJymlz1eg8LeDO8p7b4K8hvmrWSqxBriImFukan-qdgTnuCjU-h4QF-ZUcg; _uetvid=d97742f033a611efb249df9d89e67f34; JSESSIONID=\"ajax:7250445542629748653\"; liap=true; li_a=AQJ2PTEmc2FsZXNfY2lkPTkxNjg4NTYwNyUzQSUzQTYwMjQxNjcwNah5AEn6AWi9ROaR0s4ut2XYclRq; li_ep_auth_context=AHNhcHA9c2FsZXNOYXZpZ2F0b3IsYWlkPTExMzkzNjk0NixpaWQ9MTIyNDExOTg2LHBpZD0yNDc4MTUwMjcsZXhwPTE3MzYzMzM2NzM2NzUsY3VyPXRydWUsc2lkPTYwMjQxNjcwNSxjaWQ9OTE2ODg1NjA3ASCKO_6grCl0IGACzIKKx3ii5std; PLAY_LANG=en; PLAY_SESSION=eyJhbGciOiJIUzI1NiJ9.eyJkYXRhIjp7InNlc3Npb25faWQiOiI0YmI4MjRiOC0yNzQ3LTQxMDMtYjBlNS0xNDcyYjVkZTM2ZWV8MTczNDQzNDI1OSIsImFsbG93bGlzdCI6Int9IiwicmVjZW50bHktc2VhcmNoZWQiOiIiLCJyZWZlcnJhbC11cmwiOiJodHRwczovL3d3dy5saW5rZWRpbi5jb20vaGVscC9sbXMvYW5zd2VyL2ExMzEwODM4P3Ryaz1oYy1hcnRpY2xlUGFnZS1zaWRlYmFyIiwicmVjZW50bHktdmlld2VkIjoiIiwiQ1BULWlkIjoiwqHCoMKMw7XDjcKrwpgrPjI3w7bDrsO1wpPChiIsImV4cGVyaWVuY2UiOiIiLCJ0cmsiOiIifSwibmJmIjoxNzM0NDM0MzUyLCJpYXQiOjE3MzQ0MzQzNTJ9.xE7pR_cXQlRwErtd6G0uDPWzYt-3zPVp99ADTSub98o; lang=v=2&lang=en-us; li_at=AQEFARABAAAAABKA5aQAAAGT3n2UagAAAZQCihhqTQAAs3VybjpsaTplbnRlcnByaXNlQXV0aFRva2VuOmVKeGpaQUFDdGxOZFJpQ2E3MmgwTVlobTk3NTlpUkhFTUZzMklSM01VSDZoNXNqQUNBQzN1Z2gyXnVybjpsaTplbnRlcnByaXNlUHJvZmlsZToodXJuOmxpOmVudGVycHJpc2VBY2NvdW50OjExMzkzNjk0NiwyNDc4MTUwMjcpXnVybjpsaTptZW1iZXI6NDc4NjI0MDk3SD_Voyarolvls_hKa_aCMucz6-x093C4sjhSwYJ43DWeyxHqF7avCPGbO_nzp1MG8TLgsc570fuq00jdIDpQSCchcE2ZnaT7MIBXei0f-hBGS5mu57N7TKp933dTBgq1tCwShBpEJBFi7ryZDWHqS75PMnXZWd_C0aSGSZA4SfvohCEthW5aazynxDdPqz8PyzDYdg; lidc=\"b=VB97:s=V:r=V:a=V:p=V:g=3405:u=1139:x=1:i=1734607978:t=1734643188:v=2:sig=AQG-pBG5dIwmOG35vyabicRiKVkpg2VG\"; fptctx2=taBcrIH61PuCVH7eNCyH0MJojnuUODHcZ6x9WoxhgClym7WcFmG3EDHPpHIlza1H2M0OgXfxtcIRV1U1p8%252bE3oRj%252furEnPbrb%252fAVWmTvH9TJM%252fxrL4kRMSnT33doJfwfE0Bu6J85BYxSIk9cdULbHZarYcMFwUz%252fvpAfw8crVffQ%252fEiZlonq4mQD2es%252fPPkKzW5RLPX3E1zfp8gabRmVBS8GzbUXcTDf1BYne6aC9Gymeerlf4F%252fOF802AVBtX9m6reS%252bD6fMbp8nj2PhQUrxHKWC4%252fL8VJTnVhRYj7KtScmPR27jO7gKCusSyQwVmVBQl6wR4LFBtHa163rmP9RrM%252b%252bTqS92%252fwgsvZdyJew3rQ%253d; fid=AQEQnECOZo9nBgAAAZPewe2TC1vL4zyYgi5scb4vyq5540dIlaEPEUDk7zfeh_0OvsVvGlJRO3skHQ; __cf_bm=VfzdDxjrElQ5e.Ee2rQpSekH5mdw_fhrGIicgWuW1CI-1734611695-1.0.1.1-g7.FMyZ0VOz1o6FqAJvhq_H8kZWkwqnRGUzYhnn1nIhBRQrc6skn5ryTHneE966X43AoogU.A6AIKeTs6TS7bA; li_mc=MTs0MjsxNzM0NjEyMzMxOzI7MDIxQm0+zyqtB5gAAWi16bKwkFxu97NGzZc5m9IqYjjPS2I='\n",
    "\n",
    "_linkedin = None  # Initialize _linkedin as None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cookies(cookie_string):\n",
    "    # Initialize a RequestsCookieJar object\n",
    "    cookies = RequestsCookieJar()\n",
    "\n",
    "    # Split the string into individual cookies by splitting on the ';' character\n",
    "    cookie_pairs = cookie_string.strip().split(\";\")\n",
    "\n",
    "    # Iterate through each cookie key-value pair\n",
    "    for cookie in cookie_pairs:\n",
    "        if cookie.strip():  # Check if the cookie string is not empty\n",
    "            # Split each cookie on the '=' to separate the key and value\n",
    "            key, value = cookie.split(\"=\", 1)  # Limit the split to 2 parts\n",
    "            key = key.strip()  # Clean any leading/trailing whitespace\n",
    "            value = value.strip()  # Clean any leading/trailing whitespace\n",
    "\n",
    "            # Set the cookie in the RequestsCookieJar object\n",
    "            cookies.set(key, value)\n",
    "\n",
    "    return cookies\n",
    "\n",
    "def linkedin():\n",
    "    global _linkedin  # Declare _linkedin as global inside the function\n",
    "    if _linkedin is None:\n",
    "        cookies = parse_cookies(cookie_string)\n",
    "\n",
    "        _linkedin = Linkedin(\n",
    "            LINKEDIN_EMAIL,\n",
    "            LINKEDIN_PASSWORD,\n",
    "            cookies=cookies,\n",
    "        )\n",
    "    return _linkedin\n",
    "\n",
    "def extract_profile(profile_id):\n",
    "    profile_data = linkedin().get_profile(profile_id)\n",
    "    \n",
    "    return profile_data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Load and clean CSV file\n",
    "df = pd.read_csv('profiles_to_scrape.csv')\n",
    "\n",
    "# Step 1: Extract `companyName` and `companyID`\n",
    "def process_row(idx, row_data):\n",
    "    try:\n",
    "        # Add a random delay between 3 and 5 seconds\n",
    "        time.sleep(random.uniform(3, 5))\n",
    "        print(f\"Processing row {idx}\")\n",
    "\n",
    "        # Extract person posts (mock logic for example)\n",
    "        person_profile = extract_profile(row_data['Linkedin Id'])\n",
    "        return person_profile\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {idx}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Initialize the dataframe for results\n",
    "all_results = []\n",
    "\n",
    "# Sequential processing of rows\n",
    "for idx, row_data in df.iterrows():\n",
    "    result = process_row(idx, row_data)\n",
    "\n",
    "    if result:\n",
    "        all_results.append(result)\n",
    "\n",
    "    print(f\"Processed row {idx}\")\n",
    "\n",
    "# Final save to output file\n",
    "all_profiles_df = pd.DataFrame(all_results)\n",
    "all_profiles_df.to_csv('final_profiles.csv', index=False)\n",
    "print(\"Process completed. Final output saved to 'final_profiles.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('final_profiles.csv')\n",
    "\n",
    "# Convert string to list of dictionaries\n",
    "def string_to_list(string):\n",
    "    try:\n",
    "        return ast.literal_eval(string)\n",
    "    except ValueError:\n",
    "        return []\n",
    "\n",
    "df['experience'] = df['experience'].apply(string_to_list)\n",
    "\n",
    "# Function to clean and format the experience data\n",
    "def clean_experience(experience_list):\n",
    "    clean_list = []\n",
    "    for exp in experience_list:\n",
    "        title = exp.get('title', 'Unknown Title')\n",
    "        company_name = exp.get('companyName', None)\n",
    "        time_period = exp.get('timePeriod', {})\n",
    "        \n",
    "        # Format start date\n",
    "        start_date = time_period.get('startDate', {})\n",
    "        start_date_str = f\"{start_date.get('month', 1):02}/{start_date.get('year', 'Unknown')}\"\n",
    "        \n",
    "        # Format end date\n",
    "        end_date = time_period.get('endDate', {})\n",
    "        end_date_str = f\"{end_date.get('month', 1):02}/{end_date.get('year', 'Present')}\" if end_date else \"Present\"\n",
    "        \n",
    "        # Append formatted string\n",
    "        clean_list.append(f\"{title}, {company_name}: {start_date_str} - {end_date_str}\")\n",
    "    return clean_list\n",
    "\n",
    "# Function to get the last non-current company in the desired format\n",
    "def get_last_non_current_company(experience_list):\n",
    "    # Find the current company (first entry with no end date)\n",
    "    current_company = None\n",
    "    for exp in experience_list:\n",
    "        time_period = exp.get('timePeriod', {})\n",
    "        if 'endDate' not in time_period:  # This is the current company\n",
    "            current_company = exp.get('companyName', None)\n",
    "            break\n",
    "    \n",
    "    # Find the first non-current company\n",
    "    if current_company:\n",
    "        for exp in experience_list:\n",
    "            title = exp.get('title', 'Unknown Title')\n",
    "            company_name = exp.get('companyName', None)\n",
    "            time_period = exp.get('timePeriod', {})\n",
    "            if company_name != current_company:  # Ensure it's different from the current company\n",
    "                # Format start and end dates\n",
    "                start_date = time_period.get('startDate', {})\n",
    "                start_date_str = f\"{start_date.get('month', 1):02}/{start_date.get('year', 'Unknown')}\"\n",
    "                end_date = time_period.get('endDate', {})\n",
    "                end_date_str = f\"{end_date.get('year', 'Present')}\" if end_date else \"Present\"\n",
    "                # Return formatted result and the raw end_date\n",
    "                return f\"{title}, {company_name}: {start_date_str} - {end_date_str}\", company_name, end_date_str\n",
    "    return None, None, None  # Return None if no non-current company is found\n",
    "\n",
    "# Apply functions to the DataFrame\n",
    "df['Clean Experience'] = df['experience'].apply(clean_experience)\n",
    "df['Previous Company Experience'] = df['experience'].apply(\n",
    "    lambda exp_list: get_last_non_current_company(exp_list)[0]\n",
    ")\n",
    "df['Previous Company Name'] = df['experience'].apply(\n",
    "    lambda exp_list: get_last_non_current_company(exp_list)[1]\n",
    ")\n",
    "df['Previous Company End Date'] = df['experience'].apply(\n",
    "    lambda exp_list: get_last_non_current_company(exp_list)[2]\n",
    ")\n",
    "\n",
    "# Save the enriched DataFrame\n",
    "df.to_csv('final_profiles_enriched.csv', columns=['firstName', 'lastName', 'public_id', 'Clean Experience', 'Previous Company Experience','Previous Company Name', 'Previous Company End Date'], index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maquinillo-h_Y_WDD6-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
