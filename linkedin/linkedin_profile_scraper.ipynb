{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install linkedin-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.cookies import RequestsCookieJar\n",
    "from linkedin_api import Linkedin\n",
    "\n",
    "LINKEDIN_EMAIL = 'rubenlopezlozoya12@gmail.com'\n",
    "LINKEDIN_PASSWORD = 'elmaskie2'\n",
    "cookie_string = 'bscookie=\"v=1&202303061639463445695f-56e3-4100-8991-4989ced57cbeAQFetGcqbhvmdfCIHeHUPvvsf8lZkCH7\"; li_alerts=e30=; g_state={\"i_l\":0}; li_theme=light; li_theme_set=app; bcookie=\"v=2&2f4de5c0-ebaf-46bc-8f30-6395abd1d29e\"; dfpfpt=187af7de4da940f7846e9c86420c26ad; visit=v=1&M; timezone=Europe/Madrid; li_rm=AQGN_zJO-ZIfwgAAAZDmZBe9yw18cHm5CqgjeRwt4e7Iwr0BFMIf_EBTQGskP8lXcnXrlaJjAfdcbwIc7P2ZqRsuBWj69EP8KHczL1rUkr298R456bmcXr6MavbMWo3faRmKeYMg4d4KIVvv9MASE7FGtXaP-WCIufvGc99ASmM1zU8DabxWtISryAluThbdF0leFlPsd78ZDgM7dEUB_BS1UtTJqNMYITJyLVDPo47pOfYsfPxc1C9Vknf7AqoZFUGerEcus0RbqlVVx8ztL6J_SJymlz1eg8LeDO8p7b4K8hvmrWSqxBriImFukan-qdgTnuCjU-h4QF-ZUcg; _uetvid=d97742f033a611efb249df9d89e67f34; JSESSIONID=\"ajax:7250445542629748653\"; liap=true; li_a=AQJ2PTEmc2FsZXNfY2lkPTkxNjg4NTYwNyUzQSUzQTYwMjQxNjcwNah5AEn6AWi9ROaR0s4ut2XYclRq; li_ep_auth_context=AHNhcHA9c2FsZXNOYXZpZ2F0b3IsYWlkPTExMzkzNjk0NixpaWQ9MTIyNDExOTg2LHBpZD0yNDc4MTUwMjcsZXhwPTE3MzYzMzM2NzM2NzUsY3VyPXRydWUsc2lkPTYwMjQxNjcwNSxjaWQ9OTE2ODg1NjA3ASCKO_6grCl0IGACzIKKx3ii5std; PLAY_LANG=en; PLAY_SESSION=eyJhbGciOiJIUzI1NiJ9.eyJkYXRhIjp7InNlc3Npb25faWQiOiI0YmI4MjRiOC0yNzQ3LTQxMDMtYjBlNS0xNDcyYjVkZTM2ZWV8MTczNDQzNDI1OSIsImFsbG93bGlzdCI6Int9IiwicmVjZW50bHktc2VhcmNoZWQiOiIiLCJyZWZlcnJhbC11cmwiOiJodHRwczovL3d3dy5saW5rZWRpbi5jb20vaGVscC9sbXMvYW5zd2VyL2ExMzEwODM4P3Ryaz1oYy1hcnRpY2xlUGFnZS1zaWRlYmFyIiwicmVjZW50bHktdmlld2VkIjoiIiwiQ1BULWlkIjoiwqHCoMKMw7XDjcKrwpgrPjI3w7bDrsO1wpPChiIsImV4cGVyaWVuY2UiOiIiLCJ0cmsiOiIifSwibmJmIjoxNzM0NDM0MzUyLCJpYXQiOjE3MzQ0MzQzNTJ9.xE7pR_cXQlRwErtd6G0uDPWzYt-3zPVp99ADTSub98o; lang=v=2&lang=en-us; li_at=AQEFARABAAAAABKA5aQAAAGT3n2UagAAAZQCihhqTQAAs3VybjpsaTplbnRlcnByaXNlQXV0aFRva2VuOmVKeGpaQUFDdGxOZFJpQ2E3MmgwTVlobTk3NTlpUkhFTUZzMklSM01VSDZoNXNqQUNBQzN1Z2gyXnVybjpsaTplbnRlcnByaXNlUHJvZmlsZToodXJuOmxpOmVudGVycHJpc2VBY2NvdW50OjExMzkzNjk0NiwyNDc4MTUwMjcpXnVybjpsaTptZW1iZXI6NDc4NjI0MDk3SD_Voyarolvls_hKa_aCMucz6-x093C4sjhSwYJ43DWeyxHqF7avCPGbO_nzp1MG8TLgsc570fuq00jdIDpQSCchcE2ZnaT7MIBXei0f-hBGS5mu57N7TKp933dTBgq1tCwShBpEJBFi7ryZDWHqS75PMnXZWd_C0aSGSZA4SfvohCEthW5aazynxDdPqz8PyzDYdg; lidc=\"b=VB97:s=V:r=V:a=V:p=V:g=3405:u=1139:x=1:i=1734607978:t=1734643188:v=2:sig=AQG-pBG5dIwmOG35vyabicRiKVkpg2VG\"; fptctx2=taBcrIH61PuCVH7eNCyH0MJojnuUODHcZ6x9WoxhgClym7WcFmG3EDHPpHIlza1H2M0OgXfxtcIRV1U1p8%252bE3oRj%252furEnPbrb%252fAVWmTvH9TJM%252fxrL4kRMSnT33doJfwfE0Bu6J85BYxSIk9cdULbHZarYcMFwUz%252fvpAfw8crVffQ%252fEiZlonq4mQD2es%252fPPkKzW5RLPX3E1zfp8gabRmVBS8GzbUXcTDf1BYne6aC9Gymeerlf4F%252fOF802AVBtX9m6reS%252bD6fMbp8nj2PhQUrxHKWC4%252fL8VJTnVhRYj7KtScmPR27jO7gKCusSyQwVmVBQl6wR4LFBtHa163rmP9RrM%252b%252bTqS92%252fwgsvZdyJew3rQ%253d; fid=AQEQnECOZo9nBgAAAZPewe2TC1vL4zyYgi5scb4vyq5540dIlaEPEUDk7zfeh_0OvsVvGlJRO3skHQ; __cf_bm=VfzdDxjrElQ5e.Ee2rQpSekH5mdw_fhrGIicgWuW1CI-1734611695-1.0.1.1-g7.FMyZ0VOz1o6FqAJvhq_H8kZWkwqnRGUzYhnn1nIhBRQrc6skn5ryTHneE966X43AoogU.A6AIKeTs6TS7bA; li_mc=MTs0MjsxNzM0NjEyMzMxOzI7MDIxQm0+zyqtB5gAAWi16bKwkFxu97NGzZc5m9IqYjjPS2I='\n",
    "\n",
    "_linkedin = None  # Initialize _linkedin as None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cookies(cookie_string):\n",
    "    # Initialize a RequestsCookieJar object\n",
    "    cookies = RequestsCookieJar()\n",
    "\n",
    "    # Split the string into individual cookies by splitting on the ';' character\n",
    "    cookie_pairs = cookie_string.strip().split(\";\")\n",
    "\n",
    "    # Iterate through each cookie key-value pair\n",
    "    for cookie in cookie_pairs:\n",
    "        if cookie.strip():  # Check if the cookie string is not empty\n",
    "            # Split each cookie on the '=' to separate the key and value\n",
    "            key, value = cookie.split(\"=\", 1)  # Limit the split to 2 parts\n",
    "            key = key.strip()  # Clean any leading/trailing whitespace\n",
    "            value = value.strip()  # Clean any leading/trailing whitespace\n",
    "\n",
    "            # Set the cookie in the RequestsCookieJar object\n",
    "            cookies.set(key, value)\n",
    "\n",
    "    return cookies\n",
    "\n",
    "def linkedin():\n",
    "    global _linkedin  # Declare _linkedin as global inside the function\n",
    "    if _linkedin is None:\n",
    "        cookies = parse_cookies(cookie_string)\n",
    "\n",
    "        _linkedin = Linkedin(\n",
    "            LINKEDIN_EMAIL,\n",
    "            LINKEDIN_PASSWORD,\n",
    "            cookies=cookies,\n",
    "        )\n",
    "    return _linkedin\n",
    "\n",
    "def extract_profile(profile_id):\n",
    "    profile_data = linkedin().get_profile(profile_id)\n",
    "    \n",
    "    return profile_data\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processed row 0\n",
      "Processing row 1\n",
      "Processed row 1\n",
      "Processing row 2\n",
      "Processed row 2\n",
      "Processing row 3\n",
      "Processed row 3\n",
      "Processing row 4\n",
      "Processed row 4\n",
      "Processing row 5\n",
      "Processed row 5\n",
      "Processing row 6\n",
      "Processed row 6\n",
      "Processing row 7\n",
      "Processed row 7\n",
      "Processing row 8\n",
      "Processed row 8\n",
      "Processing row 9\n",
      "Processed row 9\n",
      "Processing row 10\n",
      "Processed row 10\n",
      "Processing row 11\n",
      "Processed row 11\n",
      "Processing row 12\n",
      "Processed row 12\n",
      "Processing row 13\n",
      "Processed row 13\n",
      "Processing row 14\n",
      "Processed row 14\n",
      "Processing row 15\n",
      "Processed row 15\n",
      "Processing row 16\n",
      "Processed row 16\n",
      "Processing row 17\n",
      "Processed row 17\n",
      "Processing row 18\n",
      "Processed row 18\n",
      "Processing row 19\n",
      "Processed row 19\n",
      "Processing row 20\n",
      "Processed row 20\n",
      "Processing row 21\n",
      "Processed row 21\n",
      "Processing row 22\n",
      "Processed row 22\n",
      "Processing row 23\n",
      "Processed row 23\n",
      "Processing row 24\n",
      "Processed row 24\n",
      "Processing row 25\n",
      "Processed row 25\n",
      "Processing row 26\n",
      "Processed row 26\n",
      "Processing row 27\n",
      "Processed row 27\n",
      "Processing row 28\n",
      "Processed row 28\n",
      "Processing row 29\n",
      "Processed row 29\n",
      "Processing row 30\n",
      "Processed row 30\n",
      "Processing row 31\n",
      "Processed row 31\n",
      "Processing row 32\n",
      "Processed row 32\n",
      "Processing row 33\n",
      "Processed row 33\n",
      "Processing row 34\n",
      "Processed row 34\n",
      "Processing row 35\n",
      "Processed row 35\n",
      "Processing row 36\n",
      "Processed row 36\n",
      "Processing row 37\n",
      "Processed row 37\n",
      "Processing row 38\n",
      "Processed row 38\n",
      "Processing row 39\n",
      "Processed row 39\n",
      "Processing row 40\n",
      "Processed row 40\n",
      "Processing row 41\n",
      "Processed row 41\n",
      "Processing row 42\n",
      "Processed row 42\n",
      "Processing row 43\n",
      "Processed row 43\n",
      "Processing row 44\n",
      "Processed row 44\n",
      "Processing row 45\n",
      "Processed row 45\n",
      "Processing row 46\n",
      "Processed row 46\n",
      "Processing row 47\n",
      "Processed row 47\n",
      "Processing row 48\n",
      "Processed row 48\n",
      "Processing row 49\n",
      "Processed row 49\n",
      "Processing row 50\n",
      "Processed row 50\n",
      "Processing row 51\n",
      "Processed row 51\n",
      "Processing row 52\n",
      "Processed row 52\n",
      "Processing row 53\n",
      "Processed row 53\n",
      "Processing row 54\n",
      "Processed row 54\n",
      "Processing row 55\n",
      "Processed row 55\n",
      "Processing row 56\n",
      "Processed row 56\n",
      "Processing row 57\n",
      "Processed row 57\n",
      "Processing row 58\n",
      "Processed row 58\n",
      "Processing row 59\n",
      "Processed row 59\n",
      "Processing row 60\n",
      "Processed row 60\n",
      "Processing row 61\n",
      "Processed row 61\n",
      "Processing row 62\n",
      "Processed row 62\n",
      "Processing row 63\n",
      "Processed row 63\n",
      "Processing row 64\n",
      "Processed row 64\n",
      "Processing row 65\n",
      "Processed row 65\n",
      "Processing row 66\n",
      "Processed row 66\n",
      "Processing row 67\n",
      "Processed row 67\n",
      "Processing row 68\n",
      "Processed row 68\n",
      "Processing row 69\n",
      "Processed row 69\n",
      "Processing row 70\n",
      "Processed row 70\n",
      "Processing row 71\n",
      "Processed row 71\n",
      "Processing row 72\n",
      "Processed row 72\n",
      "Processing row 73\n",
      "Processed row 73\n",
      "Processing row 74\n",
      "Processed row 74\n",
      "Processing row 75\n",
      "Processed row 75\n",
      "Processing row 76\n",
      "Processed row 76\n",
      "Processing row 77\n",
      "Processed row 77\n",
      "Processing row 78\n",
      "Processed row 78\n",
      "Processing row 79\n",
      "Processed row 79\n",
      "Processing row 80\n",
      "Processed row 80\n",
      "Processing row 81\n",
      "Processed row 81\n",
      "Processing row 82\n",
      "Processed row 82\n",
      "Processing row 83\n",
      "Processed row 83\n",
      "Processing row 84\n",
      "Processed row 84\n",
      "Processing row 85\n",
      "Processed row 85\n",
      "Processing row 86\n",
      "Processed row 86\n",
      "Processing row 87\n",
      "Processed row 87\n",
      "Processing row 88\n",
      "Processed row 88\n",
      "Processing row 89\n",
      "Processed row 89\n",
      "Processing row 90\n",
      "Processed row 90\n",
      "Processing row 91\n",
      "Processed row 91\n",
      "Processing row 92\n",
      "Processed row 92\n",
      "Processing row 93\n",
      "Processed row 93\n",
      "Processing row 94\n",
      "Processed row 94\n",
      "Processing row 95\n",
      "Processed row 95\n",
      "Processing row 96\n",
      "Processed row 96\n",
      "Processing row 97\n",
      "Processed row 97\n",
      "Processing row 98\n",
      "Processed row 98\n",
      "Processing row 99\n",
      "Processed row 99\n",
      "Processing row 100\n",
      "Processed row 100\n",
      "Processing row 101\n",
      "Processed row 101\n",
      "Processing row 102\n",
      "Processed row 102\n",
      "Processing row 103\n",
      "Processed row 103\n",
      "Processing row 104\n",
      "Processed row 104\n",
      "Processing row 105\n",
      "Processed row 105\n",
      "Processing row 106\n",
      "Processed row 106\n",
      "Processing row 107\n",
      "Processed row 107\n",
      "Processing row 108\n",
      "Processed row 108\n",
      "Processing row 109\n",
      "Processed row 109\n",
      "Processing row 110\n",
      "Processed row 110\n",
      "Processing row 111\n",
      "Processed row 111\n",
      "Processing row 112\n",
      "Processed row 112\n",
      "Processing row 113\n",
      "Processed row 113\n",
      "Processing row 114\n",
      "Processed row 114\n",
      "Processing row 115\n",
      "Processed row 115\n",
      "Processing row 116\n",
      "Processed row 116\n",
      "Processing row 117\n",
      "Processed row 117\n",
      "Processing row 118\n",
      "Processed row 118\n",
      "Processing row 119\n",
      "Processed row 119\n",
      "Processing row 120\n",
      "Processed row 120\n",
      "Processing row 121\n",
      "Processed row 121\n",
      "Processing row 122\n",
      "Processed row 122\n",
      "Processing row 123\n",
      "Processed row 123\n",
      "Processing row 124\n",
      "Processed row 124\n",
      "Processing row 125\n",
      "Processed row 125\n",
      "Processing row 126\n",
      "Processed row 126\n",
      "Processing row 127\n",
      "Processed row 127\n",
      "Process completed. Final output saved to 'final_profiles.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Load and clean CSV file\n",
    "df = pd.read_csv('profiles_to_scrape.csv')\n",
    "\n",
    "# Step 1: Extract `companyName` and `companyID`\n",
    "def process_row(idx, row_data):\n",
    "    try:\n",
    "        # Add a random delay between 3 and 5 seconds\n",
    "        time.sleep(random.uniform(3, 5))\n",
    "        print(f\"Processing row {idx}\")\n",
    "\n",
    "        # Extract person posts (mock logic for example)\n",
    "        person_profile = extract_profile(row_data['Linkedin Id'])\n",
    "        return person_profile\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {idx}: {e}\")\n",
    "        return []\n",
    "\n",
    "# Initialize the dataframe for results\n",
    "all_results = []\n",
    "\n",
    "# Sequential processing of rows\n",
    "for idx, row_data in df.iterrows():\n",
    "    result = process_row(idx, row_data)\n",
    "\n",
    "    if result:\n",
    "        all_results.append(result)\n",
    "\n",
    "    print(f\"Processed row {idx}\")\n",
    "\n",
    "# Final save to output file\n",
    "all_profiles_df = pd.DataFrame(all_results)\n",
    "all_profiles_df.to_csv('final_profiles.csv', index=False)\n",
    "print(\"Process completed. Final output saved to 'final_profiles.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('final_profiles.csv')\n",
    "\n",
    "# Convert string to list of dictionaries\n",
    "def string_to_list(string):\n",
    "    try:\n",
    "        return ast.literal_eval(string)\n",
    "    except ValueError:\n",
    "        return []\n",
    "\n",
    "df['experience'] = df['experience'].apply(string_to_list)\n",
    "\n",
    "# Function to clean and format the experience data\n",
    "def clean_experience(experience_list):\n",
    "    clean_list = []\n",
    "    for exp in experience_list:\n",
    "        title = exp.get('title', 'Unknown Title')\n",
    "        company_name = exp.get('companyName', None)\n",
    "        time_period = exp.get('timePeriod', {})\n",
    "        \n",
    "        # Format start date\n",
    "        start_date = time_period.get('startDate', {})\n",
    "        start_date_str = f\"{start_date.get('month', 1):02}/{start_date.get('year', 'Unknown')}\"\n",
    "        \n",
    "        # Format end date\n",
    "        end_date = time_period.get('endDate', {})\n",
    "        end_date_str = f\"{end_date.get('month', 1):02}/{end_date.get('year', 'Present')}\" if end_date else \"Present\"\n",
    "        \n",
    "        # Append formatted string\n",
    "        clean_list.append(f\"{title}, {company_name}: {start_date_str} - {end_date_str}\")\n",
    "    return clean_list\n",
    "\n",
    "# Function to get the last non-current company in the desired format\n",
    "def get_last_non_current_company(experience_list):\n",
    "    # Find the current company (first entry with no end date)\n",
    "    current_company = None\n",
    "    for exp in experience_list:\n",
    "        time_period = exp.get('timePeriod', {})\n",
    "        if 'endDate' not in time_period:  # This is the current company\n",
    "            current_company = exp.get('companyName', None)\n",
    "            break\n",
    "    \n",
    "    # Find the first non-current company\n",
    "    if current_company:\n",
    "        for exp in experience_list:\n",
    "            title = exp.get('title', 'Unknown Title')\n",
    "            company_name = exp.get('companyName', None)\n",
    "            time_period = exp.get('timePeriod', {})\n",
    "            if company_name != current_company:  # Ensure it's different from the current company\n",
    "                # Format start and end dates\n",
    "                start_date = time_period.get('startDate', {})\n",
    "                start_date_str = f\"{start_date.get('month', 1):02}/{start_date.get('year', 'Unknown')}\"\n",
    "                end_date = time_period.get('endDate', {})\n",
    "                end_date_str = f\"{end_date.get('year', 'Present')}\" if end_date else \"Present\"\n",
    "                # Return formatted result and the raw end_date\n",
    "                return f\"{title}, {company_name}: {start_date_str} - {end_date_str}\", company_name, end_date_str\n",
    "    return None, None, None  # Return None if no non-current company is found\n",
    "\n",
    "# Apply functions to the DataFrame\n",
    "df['Clean Experience'] = df['experience'].apply(clean_experience)\n",
    "df['Previous Company Experience'] = df['experience'].apply(\n",
    "    lambda exp_list: get_last_non_current_company(exp_list)[0]\n",
    ")\n",
    "df['Previous Company Name'] = df['experience'].apply(\n",
    "    lambda exp_list: get_last_non_current_company(exp_list)[1]\n",
    ")\n",
    "df['Previous Company End Date'] = df['experience'].apply(\n",
    "    lambda exp_list: get_last_non_current_company(exp_list)[2]\n",
    ")\n",
    "\n",
    "# Save the enriched DataFrame\n",
    "df.to_csv('final_profiles_enriched.csv', columns=['firstName', 'lastName', 'public_id', 'Clean Experience', 'Previous Company Experience','Previous Company Name', 'Previous Company End Date'], index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maquinillo-h_Y_WDD6-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
