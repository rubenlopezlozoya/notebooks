{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Company Domain Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/maquinillo-h_Y_WDD6-py3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3361\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/maquinillo-h_Y_WDD6-py3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:76\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/maquinillo-h_Y_WDD6-py3.10/lib/python3.10/site-packages/pandas/_libs/index.pyx:108\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Company Domain Name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 86\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Using ThreadPoolExecutor to run 10 concurrent rows at a time\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m---> 86\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(executor\u001b[38;5;241m.\u001b[39mmap(process_company, \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCompany Domain Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Convert the results into a DataFrame\u001b[39;00m\n\u001b[1;32m     89\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompany Domain Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinkedin_id\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/maquinillo-h_Y_WDD6-py3.10/lib/python3.10/site-packages/pandas/core/frame.py:3458\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3458\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3460\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/maquinillo-h_Y_WDD6-py3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3363\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3362\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3363\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_scalar(key) \u001b[38;5;129;01mand\u001b[39;00m isna(key) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhasnans:\n\u001b[1;32m   3366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Company Domain Name'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import http.client\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import concurrent.futures\n",
    "import re\n",
    "\n",
    "def find_linkedin_url(company_name):\n",
    "    conn = http.client.HTTPSConnection(\"google.serper.dev\")\n",
    "    payload = json.dumps({\n",
    "        \"q\": f\"{company_name} site:linkedin.com\"\n",
    "    })\n",
    "    headers = {\n",
    "        'X-API-KEY': '46e6377865b21659da0a212efadbadf2129740f5',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    conn.request(\"POST\", \"/search\", payload, headers)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read().decode(\"utf-8\")\n",
    "    results = json.loads(data)\n",
    "    if not results:\n",
    "        return None\n",
    "    if not results['organic']:\n",
    "        return None\n",
    "    website = results['organic'][0]['link']\n",
    "    return website\n",
    "\n",
    "def extract_linkedin_company_id(linkedin_url):\n",
    "    print(f\"Fetching {linkedin_url}\")\n",
    "    try:\n",
    "        zenrows_apikey = '2fb712f035250fa0feba32543c584318e4894544'\n",
    "        params = {\n",
    "            'url': linkedin_url,\n",
    "            'apikey': zenrows_apikey,\n",
    "            'js_render': 'true',\n",
    "            'custom_headers': 'true',\n",
    "            'premium_proxy': 'true',\n",
    "            'wait_for': '[data-entity-id]'\n",
    "        }\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',\n",
    "        }\n",
    "\n",
    "        retries = 4\n",
    "        backoff_factor = 2\n",
    "        initial_wait = 2  # initial wait time in seconds\n",
    "\n",
    "        for attempt in range(retries):\n",
    "            response = requests.get('https://api.zenrows.com/v1/', params=params, headers=headers)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "                # Use regex to find the number in the format urn:li:organization:<number>\n",
    "                match = re.search(r'urn:li:organization:(\\d+)', str(soup))\n",
    "\n",
    "                if match:\n",
    "                    data_entity_id = match.group(1)\n",
    "                    print(data_entity_id)\n",
    "                    return data_entity_id\n",
    "\n",
    "            print(f\"Error crawling {linkedin_url}: {response.text}, attempt {attempt + 1} of {retries}\")\n",
    "            wait_time = initial_wait * (backoff_factor ** attempt)\n",
    "            time.sleep(wait_time)  # Exponential backoff\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def get_linkedin_id(company_name):\n",
    "    linkedin_url = find_linkedin_url(company_name)\n",
    "    if not linkedin_url:\n",
    "        return None\n",
    "    linkedin_id = extract_linkedin_company_id(linkedin_url)\n",
    "    return linkedin_id\n",
    "\n",
    "def process_company(company_name):\n",
    "    linkedin_id = get_linkedin_id(company_name)\n",
    "    return company_name, linkedin_id\n",
    "\n",
    "df = pd.read_csv('domains.csv')\n",
    "\n",
    "# Using ThreadPoolExecutor to run 10 concurrent rows at a time\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=7) as executor:\n",
    "    results = list(executor.map(process_company, df['domain']))\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['domain', 'linkedin_id'])\n",
    "\n",
    "# Merge the new DataFrame with the original one\n",
    "df = df.merge(results_df, on='domain')\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('domains_enriched.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 Client Error: Bad Request for url: https://api.zenrows.com/v1/?url=capchase.com&apikey=2fb712f035250fa0feba32543c584318e4894544&js_render=true&premium_proxy=true\n",
      "Attempt 1 failed. Retrying in 2 seconds...\n",
      "400 Client Error: Bad Request for url: https://api.zenrows.com/v1/?url=capchase.com&apikey=2fb712f035250fa0feba32543c584318e4894544&js_render=true&premium_proxy=true\n",
      "Attempt 2 failed. Retrying in 4 seconds...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 107\u001b[0m, in \u001b[0;36mfetch_parsed_response\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Raise an HTTPError for bad responses (e.g., 4xx or 5xx)\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Parse the HTML response\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/maquinillo-h_Y_WDD6-py3.10/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api.zenrows.com/v1/?url=capchase.com&apikey=2fb712f035250fa0feba32543c584318e4894544&js_render=true&premium_proxy=true",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 147\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    142\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    143\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m: error_message\n\u001b[1;32m    144\u001b[0m         }\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Example return statement\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_parsed_response\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmadisonk12.us\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 124\u001b[0m, in \u001b[0;36mfetch_parsed_response\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m e  \u001b[38;5;66;03m# Re-raise the exception if max retries reached\u001b[39;00m\n\u001b[1;32m    123\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed. Retrying in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_delay\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mattempt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 124\u001b[0m             \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_delay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Exponential backoff\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m, requests\u001b[38;5;241m.\u001b[39mRequestException) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# Handle KeyError, ValueError, and HTTP/connection-related exceptions\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import re\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import urllib\n",
    "import http.client\n",
    "import json\n",
    "\n",
    "def get_domain_from_name(name):\n",
    "    URL = f\"https://company.clearbit.com/v1/domains/find?name={name}\"\n",
    "\n",
    "    CLEARBIT_KEY = 'sk_0afe7e300fe9fd1777f5e11811dc530f'\n",
    "\n",
    "    response = requests.get(URL, auth=HTTPBasicAuth(CLEARBIT_KEY, \"\"))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        return response_json[\"domain\"]\n",
    "\n",
    "    elif response.status_code == 404:\n",
    "        return None\n",
    "\n",
    "    elif response.status_code == 422:\n",
    "        print(\"Weird name:\", name)\n",
    "        return None\n",
    "\n",
    "    else:\n",
    "        print(\"Status code:\", response.status_code)\n",
    "        print(\"Body: \", response.json())\n",
    "        raise Exception(\"Weird scenario\")    \n",
    "    \n",
    "def serper_name_to_domain(company_name):\n",
    "    SERPER_KEY = '46e6377865b21659da0a212efadbadf2129740f5'\n",
    "    conn = http.client.HTTPSConnection(\"google.serper.dev\")\n",
    "    payload = json.dumps({\n",
    "    \"q\": f\"{company_name} company website\"\n",
    "    })\n",
    "    headers = {\n",
    "    'X-API-KEY': SERPER_KEY,\n",
    "    'Content-Type': 'application/json'\n",
    "    }\n",
    "    conn.request(\"POST\", \"/search\", payload, headers)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read().decode(\"utf-8\")\n",
    "    results = json.loads(data)\n",
    "    website = results['organic'][0]['link']\n",
    "\n",
    "    if 'linkedin' in website:\n",
    "        return None\n",
    "\n",
    "    return results['organic'][0]['link']\n",
    "\n",
    "\n",
    "def find_company_domain(company_name):\n",
    "    try:\n",
    "        clearbit_domain =  get_domain_from_name(company_name)\n",
    "        if clearbit_domain:\n",
    "           return clearbit_domain\n",
    "        else:\n",
    "           return serper_name_to_domain(company_name)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Parsing functions\n",
    "def get_parsed_html(html: str) -> BeautifulSoup:\n",
    "    return BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "def get_body_from_html(html: str) -> str:\n",
    "    \"\"\"\n",
    "    Gets the body of the page\n",
    "    \"\"\"\n",
    "    if not html:\n",
    "        return \"\"\n",
    "    soup = get_parsed_html(html)\n",
    "    # Extract the body content if exists, otherwise use the whole page\n",
    "    body = soup.body if soup.body else soup\n",
    "    # Get the text content and remove non-ASCII characters\n",
    "    body_text = body.get_text(\" \", strip=True)\n",
    "    return body_text.encode(\"ascii\", \"ignore\").decode()\n",
    "\n",
    "# Main function\n",
    "def fetch_parsed_response(url):\n",
    "    max_retries = 4\n",
    "    base_delay = 2  # Initial delay in seconds\n",
    "\n",
    "    try:\n",
    "        if not url:\n",
    "            raise ValueError(\"Missing or invalid 'website' key in input_data.\")\n",
    "\n",
    "        apikey = '2fb712f035250fa0feba32543c584318e4894544'  # Our Zenrows API Key\n",
    "        params = {\n",
    "            'url': 'capchase.com',\n",
    "            'apikey': apikey,\n",
    "            'js_render': 'true',\n",
    "            'premium_proxy': 'true'\n",
    "        }\n",
    "\n",
    "        attempt = 0\n",
    "        while attempt < max_retries:\n",
    "            try:\n",
    "                # Make the GET request\n",
    "                response = requests.get('https://api.zenrows.com/v1/', params=params)\n",
    "                \n",
    "                # Raise an HTTPError for bad responses (e.g., 4xx or 5xx)\n",
    "                response.raise_for_status()\n",
    "\n",
    "                # Parse the HTML response\n",
    "                parsed_body = get_body_from_html(response.text)\n",
    "\n",
    "                # Return parsed body and empty metadata\n",
    "                return {\n",
    "                    'body': parsed_body,\n",
    "                    'error': None\n",
    "                }\n",
    "\n",
    "            except requests.RequestException as e:\n",
    "                print(e)\n",
    "                attempt += 1\n",
    "                if attempt >= max_retries:\n",
    "                    raise e  # Re-raise the exception if max retries reached\n",
    "                print(f\"Attempt {attempt} failed. Retrying in {base_delay ** attempt} seconds...\")\n",
    "                time.sleep(base_delay ** attempt)  # Exponential backoff\n",
    "\n",
    "    except (KeyError, ValueError, requests.RequestException) as e:\n",
    "        # Handle KeyError, ValueError, and HTTP/connection-related exceptions\n",
    "        error_message = f\"Error occurred: {e}\"\n",
    "        print(error_message)  # Optionally log the error\n",
    "\n",
    "        return {\n",
    "            'body': None,\n",
    "            'error': error_message\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        # Catch any other unexpected exceptions\n",
    "        error_message = f\"An unexpected error occurred: {e}\"\n",
    "        print(error_message)  # Optionally log the error\n",
    "\n",
    "        return {\n",
    "            'body': None,\n",
    "            'error': error_message\n",
    "        }\n",
    "\n",
    "# Example return statement\n",
    "res = fetch_parsed_response('madisonk12.us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpurl\n"
     ]
    }
   ],
   "source": [
    "print(\"http\" + \"url\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maquinillo-h_Y_WDD6-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
