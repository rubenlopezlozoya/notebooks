{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'survey_response_id': 60880, 'reviewer_id': 62486, 'video_review': False, 'published_date': '20150904', 'product_id': 16426, 'product_uuid': '04a69f9a-4818-4716-880b-d4cf6fe77ab4', 'product': 'Toast', 'vendor_id': 13799, 'product_type': 'Software', 'name': 'Event::SurveyResponses::Viewed', 'title': '\"Excellent results\"', 'author_name': None, 'user_url': None, 'author_company_category': 'Mid-Market(51-1000 emp.)', 'rating': '4.5', 'body_like': 'The ability to digitize the paperwork needed to process employee payroll and benefits related items.', 'body_dislike': 'The usage level on our employee side. If we use it more, we could leverage its services more.', 'body_solutions': 'We have increased employee to corporate communication'}\n",
      "{'survey_response_id': 60871, 'reviewer_id': 62477, 'video_review': False, 'published_date': '20150904', 'product_id': 16426, 'product_uuid': '04a69f9a-4818-4716-880b-d4cf6fe77ab4', 'product': 'Toast', 'vendor_id': 13799, 'product_type': 'Software', 'name': 'Event::SurveyResponses::Viewed', 'title': '\"Uhlmann Price\"', 'author_name': 'James B.', 'user_url': 'https://www.g2.com/users/8e207dc5-038c-422f-8e05-9f37560ffdc7', 'author_title': 'President', 'author_company_category': 'Small-Business(50 or fewer emp.)', 'rating': '5.0', 'body_like': 'Website is very user friendly.  Very responsive if need assistance', 'body_dislike': 'Reports can be difficult to navigate and customize', 'body_solutions': 'Payroll'}\n",
      "{'survey_response_id': 60873, 'reviewer_id': 62478, 'video_review': False, 'published_date': '20150904', 'product_id': 16426, 'product_uuid': '04a69f9a-4818-4716-880b-d4cf6fe77ab4', 'product': 'Toast', 'vendor_id': 13799, 'product_type': 'Software', 'name': 'Event::SurveyResponses::Viewed', 'title': '\"We are a client and user of StratEx. \"', 'author_name': None, 'user_url': None, 'author_company_category': 'Mid-Market(51-1000 emp.)', 'rating': '5.0', 'body_like': 'Customer service and desire to grow with us.', 'body_dislike': \"No software is perfect. I think from time to time we have needed some reporting or historical data and it's been a little harder than we would like\", 'body_solutions': 'Payroll and HR streamlining. Things get done in a timely fashion.'}\n"
     ]
    }
   ],
   "source": [
    "from zenrows import ZenRowsClient\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "\n",
    "client = ZenRowsClient(\"2fb712f035250fa0feba32543c584318e4894544\")\n",
    "url = \"https://www.g2.com/products/toast/reviews?order=most_recent&page=31\"\n",
    "params = {\"js_render\":\"true\",\"premium_proxy\":\"true\",}\n",
    "\n",
    "response = client.get(url, params=params)\n",
    "\n",
    "# Assuming response.text contains the HTML source\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Remove all spans containing 'Review collected by and hosted on G2.com.'\n",
    "for span in soup.find_all('span', string=re.compile(r'Review collected by and hosted on G2.com.', re.I)):\n",
    "    span.decompose()\n",
    "\n",
    "# Find all review containers\n",
    "reviews = soup.find_all('div', itemprop='review')\n",
    "\n",
    "# List to store structured review data\n",
    "review_list = []\n",
    "\n",
    "for review in reviews:\n",
    "    review_data = {}\n",
    "    \n",
    "    # Extract metadata from 'data-track-in-viewport-options' attribute\n",
    "    data_attr = review.get('data-track-in-viewport-options')\n",
    "\n",
    "    if data_attr:\n",
    "        metadata = json.loads(data_attr.replace('&quot;', '\"'))  # Fix JSON encoding\n",
    "        review_data.update(metadata)\n",
    "\n",
    "    review_title = review.find('div', itemprop='name')\n",
    "    review_data['title'] = review_title.get_text(strip=True)\n",
    "\n",
    "    review_data['author_name'] =  None\n",
    "    review_data['user_url'] = None\n",
    "\n",
    "    # Extract reviewer name (check for anonymous vs named)\n",
    "    author_name = review.find('meta', itemprop='name')\n",
    "    author_url = review.find('meta', itemprop='url')\n",
    "\n",
    "    if author_name:\n",
    "        review_data['author_name'] = author_name['content']\n",
    "        review_data['user_url'] = author_url['content']\n",
    "\n",
    "    # Extract reviewer title and company size using div instead of span\n",
    "    title_divs = review.find_all('div', class_='mt-4th')\n",
    "    div_texts = [div.get_text(strip=True) for div in title_divs]\n",
    "    \n",
    "    if len(div_texts) == 1:\n",
    "        review_data['author_company_category'] = div_texts[0]\n",
    "    elif len(div_texts) > 1:\n",
    "        review_data['author_title'] = div_texts[0]\n",
    "        review_data['author_company_category'] = div_texts[-1]\n",
    "\n",
    "    # Extract rating\n",
    "    rating_meta = review.find('meta', itemprop='ratingValue')\n",
    "    review_data['rating'] = rating_meta['content'] if rating_meta else None\n",
    "    \n",
    "    # Extract 'like' section using regex\n",
    "    like_section = review.find('div', string=re.compile(r'What do you like best about', re.I))\n",
    "    if like_section:\n",
    "        like_text = like_section.find_next('p', class_='formatted-text')\n",
    "        review_data['body_like'] = like_text.get_text(strip=True) if like_text else None\n",
    "    \n",
    "    # Extract 'dislike' section using regex\n",
    "    dislike_section = review.find('div', string=re.compile(r'What do you dislike about', re.I))\n",
    "    if dislike_section:\n",
    "        dislike_text = dislike_section.find_next('p', class_='formatted-text')\n",
    "        review_data['body_dislike'] = dislike_text.get_text(strip=True) if dislike_text else None\n",
    "    \n",
    "    # Extract 'usage' section using regex\n",
    "    usage_section = review.find('div', string=re.compile(r'What problems .* solving and how', re.I))\n",
    "    if usage_section:\n",
    "        usage_text = usage_section.find_next('p', class_='formatted-text')\n",
    "        review_data['body_solutions'] = usage_text.get_text(strip=True) if usage_text else None\n",
    "    \n",
    "    review_list.append(review_data)\n",
    "\n",
    "# Print structured review data\n",
    "for review in review_list:\n",
    "    print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello-world-123\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "clean_string = lambda s: re.sub(r'[^a-z0-9]+', '-', s.strip().lower()).strip('-')\n",
    "\n",
    "s = \"Hello, World! + (123)\"\n",
    "print(clean_string(s))  # Output: \"HelloWorld123\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maquinillo-h_Y_WDD6-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
