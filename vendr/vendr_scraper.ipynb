{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Define the initial endpoint\n",
    "initial_endpoint = \"https://www.vendr.com/categories?_data=routes%2Fcategories._index\"\n",
    "\n",
    "# Define the headers for the second endpoint requests\n",
    "second_endpoint_headers = {\n",
    "    'accept': '*/*',\n",
    "    'accept-language': 'en-US,en;q=0.9',\n",
    "    'baggage': 'sentry-environment=production,sentry-release=1dab7cf756903936b083ffa2e91f29776517b253,sentry-public_key=5883a39b5675f77d625461a1260c675e,sentry-trace_id=bf38b4b84dbe41afb454802a31203551,sentry-sample_rate=1,sentry-transaction=routes%2Fcategories.%24categorySlug.%24subCategorySlug._index,sentry-sampled=true',\n",
    "    'cookie': '<REPLACE_WITH_YOUR_COOKIES>',\n",
    "    'priority': 'u=1, i',\n",
    "    'referer': 'https://www.vendr.com/categories/vertical-industries/agriculture?verified=false&page=1',\n",
    "    'sec-ch-ua': '\"Chromium\";v=\"130\", \"Google Chrome\";v=\"130\", \"Not?A_Brand\";v=\"99\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"macOS\"',\n",
    "    'sec-fetch-dest': 'empty',\n",
    "    'sec-fetch-mode': 'cors',\n",
    "    'sec-fetch-site': 'same-origin',\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Function to fetch data from a given URL with retries and optional headers\n",
    "def fetch_data(url, retries=3, backoff_factor=0.3, headers=None):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if attempt < retries - 1:\n",
    "                time.sleep(backoff_factor * (2 ** attempt))\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "# Function to fetch data for a category and its pages\n",
    "def fetch_category_data(category, child, page):\n",
    "    category_slug = category.get('slug')\n",
    "    child_slug = child.get('slug')\n",
    "    url = f\"https://www.vendr.com/categories/{category_slug}/{child_slug}?verified=false&page={page}&_data=routes%2Fcategories.%24categorySlug.%24subCategorySlug._index\"\n",
    "    return fetch_data(url, headers=second_endpoint_headers)\n",
    "\n",
    "# Fetch initial categories data\n",
    "categories_data = fetch_data(initial_endpoint)\n",
    "\n",
    "if categories_data is None:\n",
    "    print(\"Failed to retrieve initial categories data. Exiting.\")\n",
    "else:\n",
    "    print(\"Initial categories data fetched successfully.\")\n",
    "\n",
    "# Extract all tasks for parallel processing\n",
    "tasks = []\n",
    "all_companies = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=40) as executor:\n",
    "    for category in categories_data['categories']:\n",
    "        for child in category.get('children', []):\n",
    "            page = 1\n",
    "            total_pages = 1\n",
    "\n",
    "            # Fetch the first page to determine total pages\n",
    "            first_page_data = fetch_category_data(category, child, page)\n",
    "            if first_page_data:\n",
    "                companies = first_page_data.get('companies', [])\n",
    "                for company in companies:\n",
    "                    all_companies.append({\n",
    "                        'parent_category': category.get('name'),\n",
    "                        'parent_slug': category.get('slug'),\n",
    "                        'child_category': child.get('name'),\n",
    "                        'child_slug': child.get('slug'),\n",
    "                        'company_id': company.get('id'),\n",
    "                        'company_slug': company.get('slug'),\n",
    "                        'company_name': company.get('name'),\n",
    "                        'company_legal_name': company.get('legalName'),\n",
    "                        'company_icon': company.get('icon'),\n",
    "                        'company_description': company.get('description'),\n",
    "                        'is_vendr_verified': company.get('isVendrVerified'),\n",
    "                        'company_stats': company.get('stats')\n",
    "                    })\n",
    "                total_pages = first_page_data.get('pagination', {}).get('totalPages', 1)\n",
    "\n",
    "            # Add tasks for remaining pages\n",
    "            for page in range(2, total_pages + 1):\n",
    "                tasks.append(executor.submit(fetch_category_data, category, child, page))\n",
    "\n",
    "    # Collect results from parallel tasks\n",
    "    for future in tqdm(as_completed(tasks), total=len(tasks), desc=\"Fetching pages\"):\n",
    "        data = future.result()\n",
    "        if data:\n",
    "            companies = data.get('companies', [])\n",
    "            for company in companies:\n",
    "                all_companies.append({\n",
    "                    'parent_category': category.get('name'),\n",
    "                    'parent_slug': category.get('slug'),\n",
    "                    'child_category': child.get('name'),\n",
    "                    'child_slug': child.get('slug'),\n",
    "                    'company_id': company.get('id'),\n",
    "                    'company_slug': company.get('slug'),\n",
    "                    'company_name': company.get('name'),\n",
    "                    'company_legal_name': company.get('legalName'),\n",
    "                    'company_icon': company.get('icon'),\n",
    "                    'company_description': company.get('description'),\n",
    "                    'is_vendr_verified': company.get('isVendrVerified'),\n",
    "                    'company_stats': company.get('stats')\n",
    "                })\n",
    "\n",
    "# Convert the list of companies to a pandas DataFrame\n",
    "df_companies = pd.DataFrame(all_companies)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_companies.to_csv('vendr_all_companies.csv', index=False)\n",
    "print(\"All company data saved to vendr_all_companies.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Function to fetch details for a company slug\n",
    "def fetch_company_details_with_slug(slug, headers):\n",
    "    url = f\"https://www.vendr.com/marketplace/{slug}?_data=routes%2Fmarketplace.%24companySlug._index\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        company = data.get('company', {})\n",
    "        competitors = company.get('competitors', [])\n",
    "\n",
    "        # Extract lowest and second-lowest discounts\n",
    "        if competitors:\n",
    "            sorted_competitors = sorted(\n",
    "                competitors,\n",
    "                key=lambda c: float(c.get('stats', {}).get('averageSavingsPercent', float('inf')))\n",
    "            )\n",
    "            lowest = sorted_competitors[0] if len(sorted_competitors) > 0 else None\n",
    "            second_lowest = sorted_competitors[1] if len(sorted_competitors) > 1 else None\n",
    "            lowest_name = lowest.get('name') if lowest else None\n",
    "            lowest_discount = float(lowest.get('stats', {}).get('averageSavingsPercent', 0)) if lowest else None\n",
    "            second_lowest_name = second_lowest.get('name') if second_lowest else None\n",
    "            second_lowest_discount = float(second_lowest.get('stats', {}).get('averageSavingsPercent', 0)) if second_lowest else None\n",
    "        else:\n",
    "            lowest_name = None\n",
    "            lowest_discount = None\n",
    "            second_lowest_name = None\n",
    "            second_lowest_discount = None\n",
    "\n",
    "        # Return extracted details\n",
    "        return {\n",
    "            \"raw_data\": data,\n",
    "            'company_slug': slug,  # Include the slug for proper alignment\n",
    "            'domain': company.get('domain', None),\n",
    "            'description': company.get('description', None),\n",
    "            'competitors_data': competitors,\n",
    "            'competitor_names': ', '.join([comp.get('name', '') for comp in competitors]),\n",
    "            'communityInsights': company.get('communityInsights', []),\n",
    "            'endOfQuarterSignatureNewPurchase': company.get('discountLevers', {}).get('endOfQuarterSignatureNewPurchase', None),\n",
    "            'endOfQuarterSignatureRenewal': company.get('discountLevers', {}).get('endOfQuarterSignatureRenewal', None),\n",
    "            'expectedGrowthEconomiesOfScaleNewPurchase': company.get('discountLevers', {}).get('expectedGrowthEconomiesOfScaleNewPurchase', None),\n",
    "            'expectedGrowthEconomiesOfScaleRenewal': company.get('discountLevers', {}).get('expectedGrowthEconomiesOfScaleRenewal', None),\n",
    "            'multiYearNewPurchase': company.get('discountLevers', {}).get('multiYearNewPurchase', None),\n",
    "            'multiYearRenewal': company.get('discountLevers', {}).get('multiYearRenewal', None),\n",
    "            'hasBigSavings': company.get('hasBigSavings', None),\n",
    "            'quickSalesProcessSignatureNewPurchase': company.get('discountLevers', {}).get('quickSalesProcessSignatureNewPurchase', None),\n",
    "            'quickSalesProcessSignatureRenewal': company.get('discountLevers', {}).get('quickSalesProcessSignatureRenewal', None),\n",
    "            'averageContractValue': company.get('stats', {}).get('averageContractValue', None),\n",
    "            'averageSavingsPercent': company.get('stats', {}).get('averageSavingsPercent', None),\n",
    "            'lowest_discount_competitor': lowest_name,\n",
    "            'lowest_discount': lowest_discount,\n",
    "            'second_lowest_competitor': second_lowest_name,\n",
    "            'second_lowest_discount': second_lowest_discount\n",
    "        }\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed for company slug '{slug}': {e}\")\n",
    "        # Return default values in case of failure\n",
    "        return {\n",
    "            'company_slug': slug,\n",
    "            'domain': None,\n",
    "            'description': None,\n",
    "            'competitors_data': None,\n",
    "            'competitor_names': None,\n",
    "            'communityInsights': None,\n",
    "            'endOfQuarterSignatureNewPurchase': None,\n",
    "            'endOfQuarterSignatureRenewal': None,\n",
    "            'expectedGrowthEconomiesOfScaleNewPurchase': None,\n",
    "            'expectedGrowthEconomiesOfScaleRenewal': None,\n",
    "            'multiYearNewPurchase': None,\n",
    "            'multiYearRenewal': None,\n",
    "            'hasBigSavings': None,\n",
    "            'quickSalesProcessSignatureNewPurchase': None,\n",
    "            'quickSalesProcessSignatureRenewal': None,\n",
    "            'averageContractValue': None,\n",
    "            'averageSavingsPercent': None,\n",
    "            'lowest_discount_competitor': None,\n",
    "            'lowest_discount': None,\n",
    "            'second_lowest_competitor': None,\n",
    "            'second_lowest_discount': None\n",
    "        }\n",
    "\n",
    "# Load company slugs\n",
    "df_companies = pd.read_csv('vendr_all_companies.csv')\n",
    "company_slugs = df_companies['company_slug'].tolist()\n",
    "\n",
    "# Headers for the API requests\n",
    "marketplace_endpoint_headers = {\n",
    "    'accept': '*/*',\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Fetch details using ThreadPoolExecutor\n",
    "results = []\n",
    "max_workers = 10\n",
    "\n",
    "print(\"Fetching detailed company information...\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    future_to_slug = {executor.submit(fetch_company_details_with_slug, slug, marketplace_endpoint_headers): slug for slug in company_slugs}\n",
    "    \n",
    "    for future in tqdm(as_completed(future_to_slug), total=len(future_to_slug), desc=\"Fetching companies\"):\n",
    "        results.append(future.result())\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Merge the fetched data back into the original DataFrame\n",
    "df_enriched = pd.merge(df_companies, df_results, on='company_slug', how='left')\n",
    "\n",
    "# Save the enriched DataFrame\n",
    "df_enriched.to_csv(\"enriched_companies_with_discounts.csv\", index=False)\n",
    "\n",
    "print(\"Data fetching and enrichment complete. Saved to 'enriched_companies_with_discounts.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enriched['communityInsights'] = df_enriched['communityInsights'].apply(lambda x: None if isinstance(x, list) and len(x) == 0 else x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the enriched DataFrame to a CSV file\n",
    "\n",
    "# Convert averageSavingsPercent to numeric\n",
    "df_enriched['averageSavingsPercent'] = pd.to_numeric(df_enriched['averageSavingsPercent'])\n",
    "\n",
    "# Filter rows where averageSavingsPercent > lowest_discount\n",
    "df_filtered = df_enriched[df_enriched['averageSavingsPercent'] > df_enriched['lowest_discount']]\n",
    "\n",
    "df_filtered.to_csv('vendr_target.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"vendr_target.csv\")\n",
    "\n",
    "\n",
    "class Reviews(BaseModel):\n",
    "    quotes: list[str]\n",
    "\n",
    "# Ensure `communityInsights` is a list or string before proceeding\n",
    "df['communityInsights'] = df['communityInsights'].fillna(\"\").astype(str)\n",
    "\n",
    "# Define a function to call OpenAI\n",
    "def get_multi_year_quotes(community_insights):\n",
    "    print(f\"Processing: {community_insights[:50]}...\")  # Log the first 50 characters of the input\n",
    "    try:\n",
    "        client = OpenAI()\n",
    "\n",
    "        # Call OpenAI API with chat model\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert reviewing saas reviews regarding pricing.\"},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Your goal is to extract customer quotes mentioning having been given discounts by agreeing to commit to long term contracts (e.g annual or multi-year). Do not keep any quote mentioning discounts for other reasons (e.g mentioning competitors, acquiring more licences, etc.). This is the json with all quotes: {community_insights}\"\n",
    "                }\n",
    "            ],\n",
    "                response_format=Reviews,\n",
    "        )\n",
    "\n",
    "        print(completion.choices[0].message.parsed.quotes)\n",
    "        \n",
    "        # Extract and return the response content\n",
    "        return completion.choices[0].message.parsed.quotes\n",
    "    except Exception as e:\n",
    "        print(f\"Error for input: {community_insights[:50]}... - {e}\")\n",
    "        return None\n",
    "\n",
    "# Add a new column for multi_year_quotes\n",
    "print(\"Fetching quotes from OpenAI...\")\n",
    "tqdm.pandas()  # Enable tqdm progress bar for Pandas\n",
    "df['multi_year_quotes'] = df['communityInsights'].progress_apply(get_multi_year_quotes)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv(\"enriched_with_quotes.csv\", index=False)\n",
    "print(\"Updated DataFrame saved to 'enriched_with_quotes.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"enriched_with_quotes.csv\")\n",
    "\n",
    "\n",
    "class Reviews(BaseModel):\n",
    "    quote_1: str\n",
    "    quote_2: str\n",
    "\n",
    "# Define a function to call OpenAI\n",
    "def get_multi_year_quotes(quotes):\n",
    "    print(f\"Processing: {quotes[:50]}...\")  # Log the first 50 characters of the input\n",
    "    try:\n",
    "        client = OpenAI()\n",
    "\n",
    "        # Call OpenAI API with chat model\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert reviewing saas reviews regarding pricing.\"},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\"Your goal is to select up to two quotes from the provided list with the following criteria: \n",
    "                    1. Quotes must explicitly mention annual or multi year commitments\n",
    "                    2. Chosen quotes should be prioritized in order of higher to lower discount mentioned\n",
    "                    3. If no annual or multi year commitment is mentioned, it's ok to not select any quote, just return null value\n",
    "                    List of quotes: {quotes}\"\"\"\n",
    "                }\n",
    "            ],\n",
    "                response_format=Reviews,\n",
    "        )\n",
    "        \n",
    "        # Extract and return the response content\n",
    "        return completion.choices[0].message.parsed.quote_1, completion.choices[0].message.parsed.quote_2\n",
    "    except Exception as e:\n",
    "        print(f\"Error for input: {quotes[:50]}... - {e}\")\n",
    "        return None\n",
    "\n",
    "# Add a new column for multi_year_quotes\n",
    "print(\"Fetching quotes from OpenAI...\")\n",
    "tqdm.pandas()  # Enable tqdm progress bar for Pandas\n",
    "df[['quote_1', 'quote_2']] = pd.DataFrame(\n",
    "    df['multi_year_quotes'].progress_apply(get_multi_year_quotes).tolist(),\n",
    "    index=df.index\n",
    ")\n",
    "df.to_csv('enriched_with_quotes.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maquinillo-h_Y_WDD6-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
